<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Zhecheng Yu</title>

    <meta name="author" content="Zhecheng Yu">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2%;width:70%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Zhecheng Yu 余喆诚
                </p>
                <p>
		I'm an undergraduate student supervised by <a href='https://scholar.google.com/citations?user=60XG9FIAAAAJ&hl=en'>Prof. Yan Lyu</a> at <a href='https://cs.seu.edu.cn/bajian/' >Training Base for Top Students in Computer Science</a>, <a href='https://www.seu.edu.cn/'>Southeast University</a>, Nanjing, China. 
        I am currently working as a research assistant with <a href='https://scholar.google.com/citations?user=_bza0AoAAAAJ&hl=zh-CN'>Prof. Brian Y. Lim</a> at <a href='https://research.nus.edu.sg/ubicomplab/'>NUS Ubicomp Lab</a>.
                </p>
                <p style="text-align:center">
                  <a href="mailto:polluxiaga@gmail.com">Email</a> &nbsp;/&nbsp;
                  <a href="data/cv.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?hl=en&user=jktWnL8AAAAJ">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://github.com/Polluxiaga/">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:25%;max-width:25%">
                <a href="images/photo.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/photo.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                  I'm interested in multimodal AI, including MLLM and generative AI. First-author papers are <span class="highlight">highlighted</span>.
                </p>
              </td>
            </tr>


          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

            <tr style="padding:0px">
              <td colspan="2" style="padding:0">
                <div class="paper-entry" onmouseover="gazenav_start()" onmouseout="gazenav_stop()">
                  <div class="paper_image">
                    <div class="gazenav_image" id="gazenav_image">
                      <img src="images/gazenav_arch.jpg" alt="arch">
                    </div>
                    <img class="paper_teaser" src="images/gazenav_teaser.jpg" alt="teaser">
                  </div>

                  <div class="paper-body">
                    <a href="papers/gazenav.pdf">
                      <span class="papertitle">Learning from Human Gaze: Human-like Robot Social Navigation in Dense Crowds</span>
                    </a>
                    <span class="authors">Zhecheng Yu, Yan Lyu, Chen Yang, Tao Chen, Yishuang Zhang, Bo Ling, Peng Wang, Guanyu Gao, Weiwei Wu, Brian Y. Lim</span>
                    <span class="venue">AAAI 2026</span>
                    <span class="tldr">We introduce <strong>GazeNav</strong>, a real-world eye-tracking dataset in dense crowds, and propose <strong>Gaze2Nav</strong>, a navigation framework that mimics human gaze to identify socially salient pedestrians, achieving more human-like robot navigation.</span>
                  </div>
                </div>
              </td>
            </tr>

          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>